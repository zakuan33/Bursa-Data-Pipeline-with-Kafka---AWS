{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a222613b-021e-4040-b922-e860fd66cc2e",
   "metadata": {},
   "source": [
    "Opens the Bursa Malaysia website (Indices page).\n",
    "\n",
    "Finds the stock indices table\n",
    "\n",
    "Goes through pagination (if multiple pages)\n",
    "\n",
    "Extracts data from the HTML table(s)\n",
    "\n",
    "Appends each pageâ€™s data into a DataFrame\n",
    "\n",
    "Exports the result as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d2a9a53-7213-4e35-b41b-979a94b5566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\telet\\anaconda3\\lib\\site-packages (4.34.2)\n",
      "Requirement already satisfied: urllib3~=2.5.0 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from selenium) (2025.7.9)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from selenium) (4.14.1)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\telet\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\telet\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\telet\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\telet\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\telet\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\telet\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\telet\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\telet\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\telet\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2025.7.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e5755cd-054b-4b51-93e0-3c8d0eb6cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764f7a75-ae92-4a6a-918c-94673750ad09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1/107\n",
      "Scraping page 2/107\n",
      "Scraping page 3/107\n",
      "Scraping page 4/107\n",
      "Scraping page 5/107\n",
      "Scraping page 6/107\n",
      "Scraping page 7/107\n",
      "Scraping page 8/107\n",
      "Scraping page 9/107\n",
      "Scraping page 10/107\n",
      "Scraping page 11/107\n",
      "Scraping page 12/107\n",
      "Scraping page 13/107\n",
      "Scraping page 14/107\n",
      "Scraping page 15/107\n",
      "Scraping page 16/107\n",
      "Scraping page 17/107\n",
      "Scraping page 18/107\n",
      "Scraping page 19/107\n",
      "Scraping page 20/107\n",
      "Scraping page 21/107\n",
      "Scraping page 22/107\n",
      "Scraping page 23/107\n",
      "Scraping page 24/107\n",
      "Scraping page 25/107\n",
      "Scraping page 26/107\n",
      "Scraping page 27/107\n",
      "Scraping page 28/107\n",
      "Scraping page 29/107\n",
      "Scraping page 30/107\n",
      "Scraping page 31/107\n",
      "Scraping page 32/107\n",
      "Scraping page 33/107\n",
      "Scraping page 34/107\n",
      "Scraping page 35/107\n",
      "Scraping page 36/107\n",
      "Scraping page 37/107\n",
      "Scraping page 38/107\n",
      "Scraping page 39/107\n",
      "Scraping page 40/107\n",
      "Scraping page 41/107\n",
      "Scraping page 42/107\n",
      "Scraping page 43/107\n",
      "Scraping page 44/107\n",
      "Scraping page 45/107\n",
      "Scraping page 46/107\n",
      "Scraping page 47/107\n",
      "Scraping page 48/107\n",
      "Scraping page 49/107\n",
      "Scraping page 50/107\n",
      "Scraping page 51/107\n",
      "Scraping page 52/107\n",
      "Scraping page 53/107\n",
      "Scraping page 54/107\n",
      "Scraping page 55/107\n",
      "Scraping page 56/107\n",
      "Scraping page 57/107\n",
      "Scraping page 58/107\n",
      "Scraping page 59/107\n",
      "Scraping page 60/107\n",
      "Scraping page 61/107\n",
      "Scraping page 62/107\n",
      "Scraping page 63/107\n",
      "Scraping page 64/107\n",
      "Scraping page 65/107\n",
      "Scraping page 66/107\n",
      "Scraping page 67/107\n",
      "Scraping page 68/107\n",
      "Scraping page 69/107\n",
      "Scraping page 70/107\n",
      "Scraping page 71/107\n",
      "Scraping page 72/107\n",
      "Scraping page 73/107\n",
      "Scraping page 74/107\n",
      "Scraping page 75/107\n",
      "Scraping page 76/107\n",
      "Scraping page 77/107\n",
      "Scraping page 78/107\n",
      "Scraping page 79/107\n",
      "Scraping page 80/107\n",
      "Scraping page 81/107\n",
      "Scraping page 82/107\n",
      "Scraping page 83/107\n",
      "Scraping page 84/107\n",
      "Scraping page 85/107\n",
      "Scraping page 86/107\n",
      "Scraping page 87/107\n",
      "Scraping page 88/107\n",
      "Scraping page 89/107\n",
      "Scraping page 90/107\n",
      "Scraping page 91/107\n",
      "Scraping page 92/107\n",
      "Scraping page 93/107\n",
      "Scraping page 94/107\n",
      "Scraping page 95/107\n",
      "Scraping page 96/107\n",
      "Scraping page 97/107\n",
      "Scraping page 98/107\n",
      "Scraping page 99/107\n",
      "Scraping page 100/107\n",
      "Scraping page 101/107\n",
      "Scraping page 102/107\n",
      "Scraping page 103/107\n",
      "Scraping page 104/107\n",
      "Scraping page 105/107\n",
      "Scraping page 106/107\n",
      "Scraping page 107/107\n",
      "  CASHTAG              NAME  PRICE CLOSE     CHG     %CHG    VOLUME  HIGH  \\\n",
      "0   $REN3       3REN BERHAD  0.255  0.25   0.010   4.080%   2179100  0.26   \n",
      "1   $SEVE    7-ELEVEN M'SIA  1.990  1.99   0.000   0.000%         0  1.99   \n",
      "2   $SPEE  99 SPEED MART RE  2.250  2.26  -0.010  -0.440%   2148800  2.26   \n",
      "3   $ARNK        A-RANK BHD  0.435  0.44   0.000   0.000%         0  0.45   \n",
      "4   $A1AK       A1 A K  KOH  0.245  0.00   0.000   0.000%  21613200  0.26   \n",
      "\n",
      "    LOW        BUY (QTY)       SELL (QTY)  \n",
      "0  0.25   0.250 (495200)   0.255 (138100)  \n",
      "1  1.99      1.980 (500)   2.000 (116900)  \n",
      "2  2.23   2.250 (314500)   2.260 (294400)  \n",
      "3  0.44     0.425 (4500)     0.480 (7000)  \n",
      "4  0.25  0.245 (2661700)  0.250 (5468300)  \n",
      "Rows found: 1070\n",
      "done save file : 'bursa_market_share.csv'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Chrome\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "\n",
    "    driver.get(\"https://www.bursamarketplace.com/mkt/themarket/stock\")\n",
    "    driver.save_screenshot(\"debug_Market_Share.png\")\n",
    "\n",
    "    #no iframe on this page,removed in recent bursa redesign\n",
    "    #Wait for iframe and switch to it\n",
    "    '''\n",
    "    WebDriverWait(driver, 15).until(EC.frame_to_be_available_and_switch_to_it((By.TAG_NAME, \"iframe\")))\n",
    "    '''\n",
    "\n",
    "    #Wait for table rows rendered (instead of only table tag)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \".tb_row.tb_data\"))\n",
    "    )\n",
    "    headers = [\n",
    "    \"CASHTAG\", \"NAME\", \"PRICE\", \"CLOSE\", \"CHG\", \"%CHG\",\n",
    "    \"VOLUME\", \"HIGH\", \"LOW\", \"BUY (QTY)\", \"SELL (QTY)\"\n",
    "    ]\n",
    "    \n",
    "    '''\n",
    "    #html\n",
    "    table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "    html = table.get_attribute(\"outerHTML\")\n",
    "    '''\n",
    "\n",
    "   # wait until the data-total attribute is populated.\n",
    "    def wait_for_total_pages(driver, timeout=10):\n",
    "        end_time = time.time() + timeout\n",
    "        while time.time() < end_time:\n",
    "            try:\n",
    "                elem = driver.find_element(By.CSS_SELECTOR, \"[name='listing_paging_total']\")\n",
    "                total_text = elem.get_attribute(\"data-total\")\n",
    "                if total_text and total_text.isdigit():\n",
    "                    return int(total_text)\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(0.5)\n",
    "        raise Exception(\"Timeout: Could not read total page count from data-total attribute\")\n",
    "\n",
    "    \n",
    "    all_rows = []\n",
    "    total_pages = wait_for_total_pages(driver)\n",
    "    for page in range(1, total_pages + 1):\n",
    "        print(f\"Scraping page {page}/{total_pages}\")\n",
    "    \n",
    "        # Trigger the JS function manually using execute_script\n",
    "        js_cmd = f\"callListAjax('stock_ajax','listing',{page}, 'name', 'no');\"\n",
    "        driver.execute_script(js_cmd)\n",
    "    \n",
    "        # Wait for the page to update (wait for a specific row or CASHTAG change)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div.tb_row.tb_data\"))\n",
    "        )\n",
    "    \n",
    "        # Parse table rows using BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        for row in soup.select(\"div.tb_row.tb_data\"):\n",
    "            cols = []\n",
    "            for cell in row.select(\"div.tb_cell\"):\n",
    "                link = cell.find(\"a\")\n",
    "                text = link.text.strip() if link else cell.get_text(strip=True)\n",
    "                cols.append(text)\n",
    "            if cols:\n",
    "                all_rows.append(cols)\n",
    "\n",
    "            \n",
    "    df = pd.DataFrame(all_rows, columns=headers[:len(all_rows[0])])\n",
    "    print(df.head()) \n",
    "    print(f\"Rows found: {len(df)}\")\n",
    "    if len(df) == 0:\n",
    "        print(\"need more time for data to laod,maybe\")\n",
    "\n",
    "\n",
    "    df.index.name = \"No\"  \n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    #check data folder\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    #filename = f\"bursa_market_share{timestamp}.csv\"\n",
    "    filename = os.path.join(\"data\", f\"bursa_market_share.csv\")\n",
    "\n",
    "    df.to_csv(filename, index=True)\n",
    "    #df.to_csv(\"bursa_indices.csv\", index=False)\n",
    "    print(\"done save file : 'bursa_market_share.csv'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"error\", e)\n",
    "\n",
    "finally:\n",
    "    # Only quit if the driver exists,in real life just give up\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd3a01-7a2b-4f12-8feb-d6671dadb9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
